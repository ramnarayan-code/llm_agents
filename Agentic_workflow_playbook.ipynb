{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic Workflow playbook\n",
        "\n",
        "In this notebook, you will learn how to create\n",
        "1. LLM Agent without tools\n",
        "2. LLM Agent with tools\n",
        "3. RAG Agent\n",
        "4. Agentic workflow using langgraph"
      ],
      "metadata": {
        "id": "B3MhmtFP7ZJr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-requisites"
      ],
      "metadata": {
        "id": "ZBE3JTgg8H9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langgraph langchain langchain-openai langchain-community faiss-cpu"
      ],
      "metadata": {
        "id": "jSiac3yEVoDa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "05d25dfe-4e17-49c7-9a51-9f944b700274"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.62-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.14)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.29)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.4 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.10-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.51-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.2.10)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.59.6)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.7.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.25.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.14)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langgraph-0.2.62-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.2/138.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.2/54.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.9.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langgraph_checkpoint-2.0.10-py3-none-any.whl (37 kB)\n",
            "Downloading langgraph_sdk-0.1.51-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.1-py3-none-any.whl (29 kB)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.25.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, faiss-cpu, typing-inspect, tiktoken, pydantic-settings, langgraph-sdk, dataclasses-json, langgraph-checkpoint, langchain-openai, langgraph, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 faiss-cpu-1.9.0.post1 httpx-sse-0.4.0 langchain-community-0.3.14 langchain-openai-0.3.0 langgraph-0.2.62 langgraph-checkpoint-2.0.10 langgraph-sdk-0.1.51 marshmallow-3.25.1 mypy-extensions-1.0.0 pydantic-settings-2.7.1 python-dotenv-1.0.1 tiktoken-0.8.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Import the packages*"
      ],
      "metadata": {
        "id": "TKJvNfTjqOnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sqlite3\n",
        "\n",
        "import langgraph\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.tools import tool\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from typing import Annotated, Any, Dict, Optional, Sequence, TypedDict, List, Tuple\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langgraph.graph import END, StateGraph\n"
      ],
      "metadata": {
        "id": "XIqeXfBVWZ55"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Set up OPENAI API Key in the environment variable*"
      ],
      "metadata": {
        "id": "_-hspuhhqTrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ],
      "metadata": {
        "id": "3DBDATXzVr6y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Generic agent class definition*"
      ],
      "metadata": {
        "id": "NxbKOVqLpxNE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "  def __init__(self, prompt, tools, model):\n",
        "    self.__system_message = prompt\n",
        "    self.__tools = tools\n",
        "    self.__model = model\n",
        "    self.__memory = MemorySaver()\n",
        "\n",
        "  def create(self):\n",
        "    self.__agent = create_react_agent(self.__model, self.__tools, state_modifier=self.__system_message, checkpointer=self.__memory)\n",
        "\n",
        "  def invoke(self, input, config=None):\n",
        "    return self.__agent.invoke({\"messages\": input}, config)[\"messages\"][-1].content"
      ],
      "metadata": {
        "id": "nZDLiF0p27TT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. LLM agent without tools"
      ],
      "metadata": {
        "id": "BIZgIrx42p5H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Large Language Model (LLM) agent created without the use of additional tools can only answer general questions based on the knowledge it was trained on up to a specific point in time.\n"
      ],
      "metadata": {
        "id": "dWl40nYXpImW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Create a LLM agent with an instruction prompt*"
      ],
      "metadata": {
        "id": "wVmQUgdLpdgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatOpenAI(model=\"gpt-4o\")\n",
        "prompt = \"\"\"\n",
        "    You are an Employee Infobank. When you get questions about employees and their reporting structure, call get_employees tool\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "SahzVoVC3Awx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Agent can answer general question.*\n",
        "\n"
      ],
      "metadata": {
        "id": "Ri3b0V2npO_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "organisation_chatbot_agent = Agent(prompt, [], model)\n",
        "organisation_chatbot_agent.create()\n",
        "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
        "\n",
        "print(organisation_chatbot_agent.invoke([(\"user\", \"Who is Gandhiji?\")], config))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KrE3-Mep3Ze7",
        "outputId": "45c146b3-9fd9-4200-c8c3-d2888bedda7a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gandhiji, commonly known as Mahatma Gandhi, was a prominent leader of the Indian independence movement against British colonial rule. His full name was Mohandas Karamchand Gandhi. He is renowned for his philosophy of non-violent civil disobedience, which he used to lead India to independence, and his teachings continue to inspire movements for civil rights and freedom across the world. Gandhi is often referred to as the \"Father of the Nation\" in India.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Despite configured with a Role-specific instruction prompt, LLM agent cannot answer context-specific question but it is sensible enough to ask for more context from the user.*"
      ],
      "metadata": {
        "id": "hJuP_WGApSxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(organisation_chatbot_agent.invoke([(\"user\", \"Who is Alice?\")], config))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "N-aTtm3d363D",
        "outputId": "661f88d3-792a-460d-c39b-af1077ace9f3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could you please provide more context or specify which Alice you are referring to? There are many individuals named Alice, and additional details would help in providing a more accurate response.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. LLM Agent with tools"
      ],
      "metadata": {
        "id": "g6HLgFSN4cXy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a LLM Agent with a tool querying an example Organisation Employee database to answer employee specific questions which is out of its pre-trained knowledge."
      ],
      "metadata": {
        "id": "qkp6-md_mJi_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Create sqlite DB to host employee table*\n"
      ],
      "metadata": {
        "id": "O3TR2xW-4j2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_connection(db_file):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file)\n",
        "        return conn\n",
        "    except sqlite3.Error as e:\n",
        "        print(e)\n",
        "    return conn\n",
        "\n",
        "def create_table(conn, create_table_sql):\n",
        "    try:\n",
        "        c = conn.cursor()\n",
        "        c.execute(create_table_sql)\n",
        "    except sqlite3.Error as e:\n",
        "        print(e)\n",
        "\n",
        "def insert_employee(conn, employee):\n",
        "    sql = ''' INSERT INTO employee(id, name, designation)\n",
        "              VALUES(?,?,?) '''\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(sql, employee)\n",
        "    conn.commit()\n",
        "    return cur.lastrowid\n",
        "\n",
        "def insert_reporting(conn, reporting):\n",
        "    sql = ''' INSERT INTO reporting(id, manager_id)\n",
        "              VALUES(?,?) '''\n",
        "    cur = conn.cursor()\n",
        "    cur.execute(sql, reporting)\n",
        "    conn.commit()\n",
        "    return cur.lastrowid\n",
        "\n",
        "def main():\n",
        "    database = \"org.db\"\n",
        "\n",
        "    sql_create_employee_table = \"\"\" CREATE TABLE IF NOT EXISTS employee (\n",
        "                                        id integer PRIMARY KEY,\n",
        "                                        name text NOT NULL,\n",
        "                                        designation text NOT NULL\n",
        "                                    ); \"\"\"\n",
        "\n",
        "    sql_create_reporting_table = \"\"\" CREATE TABLE IF NOT EXISTS reporting (\n",
        "                                        id integer NOT NULL,\n",
        "                                        manager_id integer,\n",
        "                                        FOREIGN KEY (id) REFERENCES employee (id)\n",
        "                                    ); \"\"\"\n",
        "\n",
        "    conn = create_connection(database)\n",
        "\n",
        "    if conn is not None:\n",
        "        create_table(conn, sql_create_employee_table)\n",
        "        create_table(conn, sql_create_reporting_table)\n",
        "\n",
        "        employees = [(1, 'Alice', 'CEO'),\n",
        "                     (2, 'Bob', 'CTO'),\n",
        "                     (3, 'Charlie', 'COO'),\n",
        "                     (4, 'David', 'CFO'),\n",
        "                     (5, 'Eve', 'Head of Data & Analytics'),\n",
        "                     (6, 'Fred', 'HR Head')]\n",
        "\n",
        "        reportings = [(2, 1),  # Bob reports to Alice\n",
        "                      (3, 1),  # Charlie reports to Alice\n",
        "                      (4, 1),  # David reports to Alice\n",
        "                      (5, 2),  # Eve reports to Bob\n",
        "                      (6, 3)] # Fred reports to Charlie\n",
        "\n",
        "        for employee in employees:\n",
        "            insert_employee(conn, employee)\n",
        "\n",
        "        for reporting in reportings:\n",
        "            insert_reporting(conn, reporting)\n",
        "\n",
        "        print(\"Database created and tables populated successfully.\")\n",
        "    else:\n",
        "        print(\"Error! Cannot create the database connection.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sXtnTKQ-Nmj8",
        "outputId": "55ffe95d-4f3e-44d0-bd93-4861b8ef5395"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database created and tables populated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Tool function definition to retrieve the employee list from an employee database*"
      ],
      "metadata": {
        "id": "ou-Ozqhy41Pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def get_employees():\n",
        "  \"\"\"Gets the employees list.\"\"\"\n",
        "  conn = create_connection(\"org.db\")\n",
        "  employees = {}\n",
        "  try:\n",
        "      cur = conn.cursor()\n",
        "      cur.execute(\"\"\"\n",
        "          SELECT e.id, e.name, e.designation, r.manager_id, m.name as manager_name\n",
        "          FROM employee e\n",
        "          LEFT JOIN reporting r ON e.id = r.id\n",
        "          LEFT JOIN employee m ON r.manager_id = m.id\n",
        "      \"\"\")\n",
        "      rows = cur.fetchall()\n",
        "      for row in rows:\n",
        "          emp_id, name, designation, manager_id, manager_name = row\n",
        "          employees[emp_id] = {\n",
        "              \"name\": name,\n",
        "              \"designation\": designation,\n",
        "              \"manager_id\": manager_id,\n",
        "              \"manager_name\": manager_name\n",
        "          }\n",
        "  except sqlite3.Error as e:\n",
        "      print(e)\n",
        "  return employees"
      ],
      "metadata": {
        "id": "yCpt-2b4av0Z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*LLM Agent is created with \"get_employees\" tool*\n",
        "\n",
        "You can observe that LLM agent has the capability now to answer employee-specific questions"
      ],
      "metadata": {
        "id": "BMcyROk25GoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [get_employees]\n",
        "organisation_chatbot_agent = Agent(prompt, tools, model)\n",
        "organisation_chatbot_agent.create()\n",
        "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
        "\n",
        "print(organisation_chatbot_agent.invoke([(\"user\", \"Who is Alice?\")], config))\n",
        "print(organisation_chatbot_agent.invoke([(\"user\", \"How many employees are reporting to Alice?\")], config))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xzPDHll3dT2t",
        "outputId": "cea13816-6955-49ad-b4ee-f7f60e49e1e8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alice is the CEO of the company. She has no manager, as she holds the top executive position.\n",
            "Alice, the CEO, has three employees directly reporting to her. They are:\n",
            "\n",
            "1. Bob, the CTO\n",
            "2. Charlie, the COO\n",
            "3. David, the CFO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. RAG Agent"
      ],
      "metadata": {
        "id": "BSIyBj4W5RAG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Retrieval-Augmented Generation (RAG) agent is like a smart assistant for complex questions. Imagine you have a friend who has access to an enormous library and a fast way to find the exact information you need. This friend also has a talent for putting together the information into clear, coherent answers. That's what a RAG agent does – it tackles your complex questions by searching through a wealth of information and generating detailed responses based on what it finds."
      ],
      "metadata": {
        "id": "sV4kMYE4ri2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison between RAG Agent and LLM Agent with Tools\n",
        "\n",
        "**RAG Agent:**\n",
        "\n",
        "A RAG agent excels at handling complex, nuanced queries. When you ask a complicated question that requires gathering and combining information from various sources, the RAG agent searches through its vast dataset, retrieves the most relevant pieces, and synthesizes a comprehensive response. This makes it highly effective for answering intricate questions where the answer isn't straightforward or readily available.\n",
        "\n",
        "**LLM Agent with Tools:**\n",
        "\n",
        "An LLM (Large Language Model) agent with tools is designed to be a quick, reliable responder for clear and definite questions. These tools might include access to calculators, databases, or APIs that provide precise data. For instance, if you need a specific fact or a clear-cut answer, the LLM agent uses these tools to provide a speedy and accurate response. However, it might struggle with more complex queries that require nuanced understanding and extensive information retrieval."
      ],
      "metadata": {
        "id": "EsqRS6JNtMG9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*RAG Agent class definition which can provide department location info of our example organisation*"
      ],
      "metadata": {
        "id": "5cb-I53Xtl92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LLMRAGBasedNavigator:\n",
        "    def __init__(self):\n",
        "        self.__model = ChatOpenAI()\n",
        "        self.__navigator_prompt_template = template = \"\"\"\n",
        "                    You are a department navigator. Provide the department location based on the context:\n",
        "                    {context}\n",
        "\n",
        "                    Question: {question}\n",
        "                  \"\"\"\n",
        "\n",
        "    def __create_retreiver(self, context):\n",
        "        self.__vectorstore = FAISS.from_texts(context, embedding=OpenAIEmbeddings())\n",
        "        self.__retriever = self.__vectorstore.as_retriever()\n",
        "\n",
        "    def __create_prompt(self):\n",
        "        self.__prompt = ChatPromptTemplate.from_template(self.__navigator_prompt_template)\n",
        "\n",
        "    def create_llm_chat_context(self, context):\n",
        "        self.__create_retreiver(context)\n",
        "        self.__create_prompt()\n",
        "        self.__llm_chain = (\n",
        "            {\"context\": self.__retriever, \"question\": RunnablePassthrough()}\n",
        "            | self.__prompt\n",
        "            | self.__model\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "\n",
        "    def chat_with_llm(self, question):\n",
        "        response = self.__llm_chain.invoke(question)\n",
        "        return response\n",
        "\n",
        "context_for_department_navigation =  [\"HR is located on the first floor\",\n",
        "                                  \"Finance is located on the second floor\",\n",
        "                                  \"Data & Analytics is located on the third floor\",\n",
        "                                  \"Sales is located on the fourth floor\",\n",
        "                                  \"Marketing is located on the fifth floor\"]\n",
        "llm_navigator = LLMRAGBasedNavigator()\n",
        "llm_navigator.create_llm_chat_context(context_for_department_navigation)\n",
        "\n",
        "llm_navigator.chat_with_llm(\"where is HR located?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HFbbTq6skFBR",
        "outputId": "c384daa7-616f-4e1b-84a3-bd37fda387c5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'HR is located on the first floor.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Agentic Workflow using langgraph"
      ],
      "metadata": {
        "id": "k5zShTEd5fVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we will build an all-in-one Organisation chatbot agent by integrating both LLM agent with tools and RAG agent"
      ],
      "metadata": {
        "id": "Phjydh7tt1tw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Definition of agent state attributes used in the agentic workflow*"
      ],
      "metadata": {
        "id": "QaXbUuqWvHDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    query: Sequence[BaseMessage]\n",
        "    result: str"
      ],
      "metadata": {
        "id": "IbGoo8Fqk2sm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Definition of agent functions*"
      ],
      "metadata": {
        "id": "r_w-nVyNvWQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on LLM agent with tools\n",
        "def org_chatbot(state):\n",
        "    print(f'Org agent:')\n",
        "    query = state['query']\n",
        "    prompt = \"\"\"\n",
        "      You are an Organisation chatbot. Follow the below rules:\n",
        "      1. When you get questions about employees and their reporting structure, call get_employees tool\n",
        "      2. When you get questions about departments, route the query to \"department_navigator\" agent\n",
        "    \"\"\"\n",
        "    tools = [get_employees]\n",
        "    organisation_chatbot_agent = Agent(prompt, tools, model)\n",
        "    organisation_chatbot_agent.create()\n",
        "    config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
        "    result = organisation_chatbot_agent.invoke([(\"user\", query)], config)\n",
        "    return {'result': result}\n",
        "\n",
        "# Routing the department location questions to RAG agent \"department_navigator\"\n",
        "def route(state):\n",
        "    result = state['result']\n",
        "    if \"department_navigator\" in result:\n",
        "        return \"department_navigator\"\n",
        "    else:\n",
        "        return END\n",
        "\n",
        "# Based on RAG agent\n",
        "def department_navigator(state):\n",
        "    print(f'department_navigator agent:')\n",
        "    query = state['query']\n",
        "    result = llm_navigator.chat_with_llm(query)\n",
        "    return {'result':result}"
      ],
      "metadata": {
        "id": "55DpJIzrk6ce"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Organisation Chatbot agent follows ReAct prompting technique which thinks and decides to take action on how to answer general and context-specific questions like:\n",
        "*   Answers the general questions based on its pre-trained knowledge\n",
        "\n",
        "*   Responds to the context-specific questions either by using tool or by routing to the another specialised agent\n",
        "\n",
        "Many specialised agents like department-specific, process-specific can be developed and connected to the Organisation chatbot agent to expand its capability to answer more context-specific complex questions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qliWFc-V5p-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Agentic workflow definition using langgraph*"
      ],
      "metadata": {
        "id": "DEu0RsHiyFjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Define the nodes\n",
        "workflow.add_node(\"org_chatbot\", org_chatbot)\n",
        "workflow.add_node(\"department_navigator\", department_navigator)\n",
        "\n",
        "# Build graph\n",
        "workflow.set_entry_point(\"org_chatbot\")\n",
        "workflow.add_conditional_edges(\"org_chatbot\", route)\n",
        "workflow.add_edge(\"org_chatbot\", END)\n",
        "\n",
        "app = workflow.compile()\n"
      ],
      "metadata": {
        "id": "ppobfjzJk6XP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Organisation chatbot demo*"
      ],
      "metadata": {
        "id": "8b8REHp4yKFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Welcome to Virtual Org!. I am Virtual Org Chatbot. I can answer to both general and company-specific questions\")\n",
        "\n",
        "while True:\n",
        "  query_input = input('Enter the query: ')\n",
        "  if query_input == 'exit':\n",
        "    print(\"See you next time...\")\n",
        "    break\n",
        "\n",
        "  for stream_msg in app.stream({\"query\": query_input}):\n",
        "    if \"__end__\" not in stream_msg:\n",
        "        if \"org_chatbot\" in stream_msg:\n",
        "          print(stream_msg[\"org_chatbot\"])\n",
        "        elif \"department_navigator\" in stream_msg:\n",
        "          print(stream_msg[\"department_navigator\"])\n",
        "        print(\"----\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "tAY8ZGDBpcuW",
        "outputId": "a35b6b69-9c87-4199-b061-9da78b6bc120"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to Virtual Org!. I am Virtual Org Chatbot. I can answer to both general and company-specific questions\n",
            "Enter the query: Who is the CEO?\n",
            "Org agent:\n",
            "{'result': 'The CEO is Alice.'}\n",
            "----\n",
            "Enter the query: Where is HR located?\n",
            "Org agent:\n",
            "{'result': 'For questions about departments, I\\'ll direct you to our \"department_navigator\" agent who can assist you with information about HR\\'s location.'}\n",
            "----\n",
            "department_navigator agent:\n",
            "{'result': 'HR is located on the first floor.'}\n",
            "----\n",
            "Enter the query: How many departments?\n",
            "Org agent:\n",
            "{'result': 'I recommend you to speak with the \"department_navigator\" agent, as it specializes in handling queries related to departments.'}\n",
            "----\n",
            "department_navigator agent:\n",
            "{'result': 'There are four departments. \\nFinance is located on the second floor\\nHR is located on the first floor\\nMarketing is located on the fifth floor\\nSales is located on the fourth floor\\n'}\n",
            "----\n",
            "Enter the query: But you missed Data & Analytics department. where is it?\n",
            "Org agent:\n",
            "{'result': 'Please hold on while I route your query to the \"department_navigator\" for more information on the Data & Analytics department.'}\n",
            "----\n",
            "department_navigator agent:\n",
            "{'result': 'Data & Analytics department is located on the third floor.'}\n",
            "----\n",
            "Enter the query: Now how many departments?\n",
            "Org agent:\n",
            "{'result': 'For queries regarding the number of departments, please reach out to the \"department_navigator\" agent.'}\n",
            "----\n",
            "department_navigator agent:\n",
            "{'result': 'There are four departments: HR, Finance, Marketing, and Sales.'}\n",
            "----\n",
            "Enter the query: exit\n",
            "See you next time...\n"
          ]
        }
      ]
    }
  ]
}
